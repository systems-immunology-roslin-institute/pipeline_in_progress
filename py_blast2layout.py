#### SCRIPT DESCRIPTION ####
# This takes the Blast+ output and make a .layout file with it

#### INPUT / OUPUT ####
# INPUT (from .sh):
# - cache folder
# - gene of interest
# OTHER ASSUMED INPUTS (WITHIN CACHE FOLDER)
# The script assumes that the corresponding -blast.tab, _grouped_reads.fsa and .gtf/gff2/gff3 files are in the corresponding folders in within the cache folder
# - GENENAME-blast.tab : blastn results from BLAST plus. Generated by the main .sh script, using blastn.
# - BAMFILENAME_grouped_reads.fsa : details on the groups of read, including counts, sequence, and start-end loci. Generated by py_sam2fasta.py
# The script has only been optimalised to understand .gtf, .gff3 gene/exon annotation formats

#### INPUT BACKGROUND ####
# The columns in the BLAST plus (blastn) output are:
# [0] qseqid : query (e.g., gene) sequence id
# [1] sseqid : subject (e.g., reference genome) sequence id
# [2] pident : percentage of identical matches
# [3] length : alignment length
# [4] mismatch : number of mismatches
# [5] gapopen : number of gap openings
# [6] qstart : start of alignment in query
# [7] qend : end of alignment in query
# [8] start : start of alignment in subject
# [9] send : end of alignment in subject
# [10] evalue : expect value
# [11] bitscore : bit score
# Bit-score =  A log-scaled version of a score. In the context of sequence alignments, a score is a numerical value that describes the overall quality of an alignment. Higher numbers correspond to higher similarity. The score scale depends on the scoring system used (substitution matrix, gap penalty).


#### STEP 0 : SETTINGS ####
#similarity_filter = 98 # threshold for % similarity in the blast result
#coverage_filter = 30 # the % of bases being aligned (number of bases aligned * 2 / the sum of length from both sequences)
#bit_score_filter =  100 # threshold for bit score in the blast result 

#### Import library ####
import re
import sys
import os
import py_fun
from py_fun.coord_comp import is_number

#### Read in inputs ####
in_fp_cache =  sys.argv[1] # cache folder
in_gene_name = sys.argv[2] # gene_name
in_fp_out = sys.argv[3] # output folder
similarity_filter = float(sys.argv[4]) # output folder
coverage_filter = float(sys.argv[5])
unification_method = sys.argv[6]
coord_range = sys.argv[7]

os.makedirs(in_fp_out) if not os.path.exists(in_fp_out) else 0
in_fp_blast = "%s/%s/blast/%s-blast.tab" %(in_fp_cache, in_gene_name, in_gene_name)
in_fp_fsa = in_fp_cache + '/' + in_gene_name + '/fsa/' + in_gene_name + '.fsa'
in_fp_node_annotation = "%s/%s/node/%s_node_annotation.txt" %(in_fp_cache, in_gene_name, in_gene_name)
out_dir_gml = "%s/%s"%(in_fp_out, in_fp_cache.split("/")[1])
out_fp_gml="%s/%s_%s_sim%d_cov%d.gml" %(out_dir_gml, in_gene_name, unification_method, similarity_filter, coverage_filter)
if not os.path.exists(out_dir_gml):
    os.makedirs(out_dir_gml)

#### Use inputs to check for the required files (blast results, grouped_reads characteristiscs, and gene-specific gtf) from the cache folder
#in_fp_blast= in_fp_cache + '/' + in_gene_name + '/blast/' + in_gene_name + '-blast.tab'


#### STEP 1: record the sequence for each node ####
current_node = None
node_annotation = {}

with open(in_fp_fsa, "r") as fsa:
    for line in fsa:
        line = line.rstrip("\r\n")
        if not current_node :
            current_node = line[1:len(line)] # remove the first character >
            node_annotation.update({current_node:{}}) if current_node != "" else 0
        else:
            node_annotation[current_node]['seq_len'] = len(line)       
            current_node = None

#### STEP 2: read in node annotation ####
with open(in_fp_node_annotation, "r") as node_annotation_txt:
    for line_num, line in enumerate(node_annotation_txt):
        line = line.rstrip("\r\n")
        line = line.split("\t")
        if line_num==0:
            annotation_header = line[1:len(line)]
        else:
            node_annotation[line[0]].update({'annotation':line[1:len(line)]})

#### STEP 3: go through blast result ####
node_id_old2new = {} # as gml requires the input node to be sequential, and some nodes might not be present in the final graph, conversion is required
node_id_new2old = {} # as gml requires the input node to be sequential, and some nodes might not be present in the final graph, conversion is required
blast_paired_dict = {}
out_node_num_id = 1;

# Read through the blast result file once to get summary statistics.
# print out :
# - total number of results
# - count for each blast score
# - count for 
# - average overlap
# Read in the blast results. Remove redundency.
with open(in_fp_blast, "r") as blast_result:
    for line in blast_result:
        line = line.rstrip("\n\r")
        if re.match(r'^#', line):
            next
        elif line != "":
            values = line.split("\t")
            read_ids = [values[0], values[1]] 
            read_ids.sort() # the read_groups for each comparison was sorted alphabetically to remove redundancy (i.e. [group1 vs group2] AND [group2 vs group1] both become [group1 vs group2])
            blast_score = float(values[-1])
            if (float(values[2]) > similarity_filter) : # set the % similarity threshold 
                if not read_ids[0] == read_ids[1]: # ignore if the read is compared to itself in the blast result
                    # check the coverage and whether the coverage is more than 30% of the total number of nucleotide length
                    alignment_length = values[3]
                    alignment_coverage = (float(alignment_length) * 2 / float(node_annotation[read_ids[0]]['seq_len'] + node_annotation[read_ids[1]]['seq_len'])) * 100
                    if alignment_coverage > coverage_filter:
                        # Define conversions between the descriptive id for the node and the numeric id
                        new_readids = []
                        for current_read_id in read_ids:
                            if current_read_id not in node_id_old2new:
                                node_id_old2new[current_read_id] = out_node_num_id
                                node_id_new2old[out_node_num_id] = current_read_id
                                out_node_num_id +=1
                                new_readids.append(node_id_old2new[current_read_id])
                            else:
                                new_readids.append(node_id_old2new[current_read_id])
                        new_readids.sort()
                        blast_paired_dict.update({new_readids[0]:{}}) if not new_readids[0] in blast_paired_dict else 0
                        blast_paired_dict[new_readids[0]].update({new_readids[1]:blast_score}) if not new_readids[1] in blast_paired_dict[new_readids[0]] else 0

#### STEP 4: Go through node information and print out only those with at least 1 edge ####
# print out node information
gml=open(out_fp_gml, 'w+')
gml.write("graph[\n")
for node_idx in range(1, out_node_num_id):
    current_node=node_id_new2old[node_idx]
    node_label = node_annotation[current_node]['annotation'][0] # the node_id is stored in index 1 in node_annotation 
    gml.write("  node [\n")
    gml.write("    id %d\n" %(node_idx))
    gml.write("    label \"%s\"\n"%(node_label))
    for idx in range(1, len(annotation_header)):
        attribute_val=node_annotation[current_node]['annotation'][idx]
        if is_number(attribute_val):
            attribute_val=float(attribute_val)
        else:
            attribute_val="\"%s\""%(attribute_val)
        gml.write("    %s %s\n"%(annotation_header[idx], attribute_val))
    gml.write("  ]\n")
    
#### STEP 5: print out edge information ####
for node1 in blast_paired_dict:
    for node2, blastscore in blast_paired_dict[node1].items():
        gml.write("  edge [\n")
        gml.write("    source %d\n" %(node1))
        gml.write("    target %d\n" %(node2))
        gml.write("    blast %.2f\n"%(blastscore))
        gml.write("  ]\n")
gml.write("]\n")
gml.close()

